{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7899275,"sourceType":"datasetVersion","datasetId":4638965},{"sourceId":8094226,"sourceType":"datasetVersion","datasetId":4778935}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-22T17:22:52.831535Z","iopub.execute_input":"2024-04-22T17:22:52.831912Z","iopub.status.idle":"2024-04-22T17:22:53.190454Z","shell.execute_reply.started":"2024-04-22T17:22:52.831882Z","shell.execute_reply":"2024-04-22T17:22:53.189588Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/headcut-collection/Headcut CSVs/Riehle_2A_Project_Structures.csv\n/kaggle/input/headcut-collection/Headcut CSVs/Riehle_3_Long_Pro.csv\n/kaggle/input/headcut-collection/Headcut CSVs/Riehle_2B_Project_Structures.csv\n/kaggle/input/headcut-collection/Headcut CSVs/Riehle_1A_Project_Structures.csv\n/kaggle/input/headcut-collection/Headcut CSVs/Riehle_4_Long_Pro.csv\n/kaggle/input/headcut-collection/Headcut CSVs/Riehle_1B_Project_Structures.csv\n/kaggle/input/headcut-collection/Headcut CSVs/Riehle_2B_Long_Pro.csv\n/kaggle/input/headcut-collection/Headcut CSVs/Riehle_3_Project_Structures.csv\n/kaggle/input/headcut-collection/Headcut CSVs/Riehle_2A_Long_Pro.csv\n/kaggle/input/headcut-collection/Headcut CSVs/Riehle_1B_Long_Pro.csv\n/kaggle/input/headcut-collection/Headcut CSVs/Riehle_4_Project_Structures.csv\n/kaggle/input/headcut-collection/Headcut CSVs/Riehle_1A_Long_Pro.csv\n/kaggle/input/riehle-1/Riehle_1_Project_Structures.csv\n/kaggle/input/riehle-1/Riehle_1_Long_Pro.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"stream_profile_df = pd.read_csv('/kaggle/input/riehle-1/Riehle_1_Long_Pro.csv')\nstream_profile_df = stream_profile_df.rename(stream_profile_df.iloc[0]).iloc[1:]\nstream_profile_df.columns = ['Dist M', 'X', 'Y', 'Elev ft']\nstream_profile_df","metadata":{"execution":{"iopub.status.busy":"2024-04-22T17:22:53.274946Z","iopub.execute_input":"2024-04-22T17:22:53.275612Z","iopub.status.idle":"2024-04-22T17:22:53.299737Z","shell.execute_reply.started":"2024-04-22T17:22:53.275582Z","shell.execute_reply":"2024-04-22T17:22:53.298892Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"          Dist M            X            Y      Elev ft\n1              0  495998.0819  4794269.644  4872.834961\n2    1.263171269   495998.744  4794268.568  4872.605469\n3    2.526342538   495999.406  4794267.492  4872.506836\n4    3.789513807   496000.068  4794266.416  4872.375488\n5    5.052685076    496000.73   4794265.34  4872.178711\n..           ...          ...          ...          ...\n579  738.2102804  496079.3353  4793625.201  4793.208496\n580   739.468345   496079.651  4793623.984  4793.175781\n581  740.5064947  496079.8314  4793622.961  4793.175781\n582  741.5446445  496080.0118  4793621.939  4793.175781\n583  742.5827942  496080.1922  4793620.916  4793.110352\n\n[583 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dist M</th>\n      <th>X</th>\n      <th>Y</th>\n      <th>Elev ft</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>495998.0819</td>\n      <td>4794269.644</td>\n      <td>4872.834961</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.263171269</td>\n      <td>495998.744</td>\n      <td>4794268.568</td>\n      <td>4872.605469</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.526342538</td>\n      <td>495999.406</td>\n      <td>4794267.492</td>\n      <td>4872.506836</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.789513807</td>\n      <td>496000.068</td>\n      <td>4794266.416</td>\n      <td>4872.375488</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5.052685076</td>\n      <td>496000.73</td>\n      <td>4794265.34</td>\n      <td>4872.178711</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>579</th>\n      <td>738.2102804</td>\n      <td>496079.3353</td>\n      <td>4793625.201</td>\n      <td>4793.208496</td>\n    </tr>\n    <tr>\n      <th>580</th>\n      <td>739.468345</td>\n      <td>496079.651</td>\n      <td>4793623.984</td>\n      <td>4793.175781</td>\n    </tr>\n    <tr>\n      <th>581</th>\n      <td>740.5064947</td>\n      <td>496079.8314</td>\n      <td>4793622.961</td>\n      <td>4793.175781</td>\n    </tr>\n    <tr>\n      <th>582</th>\n      <td>741.5446445</td>\n      <td>496080.0118</td>\n      <td>4793621.939</td>\n      <td>4793.175781</td>\n    </tr>\n    <tr>\n      <th>583</th>\n      <td>742.5827942</td>\n      <td>496080.1922</td>\n      <td>4793620.916</td>\n      <td>4793.110352</td>\n    </tr>\n  </tbody>\n</table>\n<p>583 rows Ã— 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"structures_df = pd.read_csv('/kaggle/input/riehle-1/Riehle_1_Project_Structures.csv')\nstructures_df = structures_df.rename(columns={'y_proj': 'Y', 'x_proj': 'X'})\nstructures_df","metadata":{"execution":{"iopub.status.busy":"2024-04-22T17:22:53.493927Z","iopub.execute_input":"2024-04-22T17:22:53.494479Z","iopub.status.idle":"2024-04-22T17:22:53.518354Z","shell.execute_reply.started":"2024-04-22T17:22:53.494453Z","shell.execute_reply":"2024-04-22T17:22:53.517534Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"        type         ident   Latitude   Longitude            Y            X  \\\n0   WAYPOINT   RIEHLE 1-07  43.300586 -105.049715  4794195.671  495968.4718   \n1   WAYPOINT   RIEHLE 1-04  43.299027 -105.050437  4794022.573  495909.8059   \n2   WAYPOINT   RIEHLE 1-01  43.298433 -105.049843  4793956.578  495957.9471   \n3   WAYPOINT   RIEHLE 1-09  43.301886 -105.049627  4794340.038  495975.6952   \n4   WAYPOINT   RIEHLE 1-08  43.300821 -105.049454  4794221.757  495989.6569   \n5   WAYPOINT   RIEHLE 1-06  43.299888 -105.050330  4794118.185  495918.5425   \n6   WAYPOINT   RIEHLE 1-05  43.299390 -105.050454  4794062.887  495908.4514   \n7   WAYPOINT   RIEHLE 1-02  43.298728 -105.050197  4793989.382  495929.2187   \n8   WAYPOINT   RIEHLE 1-03  43.298965 -105.050397  4794015.678  495913.0101   \n9   WAYPOINT  RIEHLE 1-101  43.295872 -105.048572  4793672.122  496060.8806   \n10  WAYPOINT  RIEHLE 1-102  43.296017 -105.048671  4793688.225  496052.8807   \n11  WAYPOINT  RIEHLE 1-103  43.296140 -105.048585  4793701.847  496059.8165   \n12  WAYPOINT  RIEHLE 1-104  43.296230 -105.048663  4793711.847  496053.5120   \n13  WAYPOINT  RIEHLE 1-109  43.296734 -105.048855  4793767.847  496037.9898   \n14  WAYPOINT  RIEHLE 1-108  43.296600 -105.048807  4793753.018  496041.8808   \n15  WAYPOINT  RIEHLE 1-107  43.296550 -105.048807  4793747.398  496041.8808   \n16  WAYPOINT  RIEHLE 1-106  43.296455 -105.048612  4793736.827  496057.7109   \n17  WAYPOINT  RIEHLE 1-100  43.295859 -105.048531  4793670.706  496064.2344   \n18  WAYPOINT  RIEHLE 1-105  43.296445 -105.048622  4793735.773  496056.8265   \n19  WAYPOINT  Riehle 1-110  43.297916 -105.049595  4793899.195  495978.0270   \n20  WAYPOINT  RIEHLE 1-111  43.298726 -105.050188  4793989.098  495929.9958   \n21  WAYPOINT  RIEHLE 1-112  43.299875 -105.050298  4794116.776  495921.0939   \n\n           comment  \n0        ZB 12-4-2  \n1      RRD 10-10-1  \n2              NaN  \n3   Mdw small chnl  \n4          10-15-1  \n5               WF  \n6           15-8-1  \n7         8-14-2.5  \n8        12.5-17-2  \n9              NaN  \n10             NaN  \n11             NaN  \n12             NaN  \n13             NaN  \n14             NaN  \n15             NaN  \n16             NaN  \n17             NaN  \n18             NaN  \n19             NaN  \n20             NaN  \n21             NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>ident</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Y</th>\n      <th>X</th>\n      <th>comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>WAYPOINT</td>\n      <td>RIEHLE 1-07</td>\n      <td>43.300586</td>\n      <td>-105.049715</td>\n      <td>4794195.671</td>\n      <td>495968.4718</td>\n      <td>ZB 12-4-2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>WAYPOINT</td>\n      <td>RIEHLE 1-04</td>\n      <td>43.299027</td>\n      <td>-105.050437</td>\n      <td>4794022.573</td>\n      <td>495909.8059</td>\n      <td>RRD 10-10-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>WAYPOINT</td>\n      <td>RIEHLE 1-01</td>\n      <td>43.298433</td>\n      <td>-105.049843</td>\n      <td>4793956.578</td>\n      <td>495957.9471</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>WAYPOINT</td>\n      <td>RIEHLE 1-09</td>\n      <td>43.301886</td>\n      <td>-105.049627</td>\n      <td>4794340.038</td>\n      <td>495975.6952</td>\n      <td>Mdw small chnl</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>WAYPOINT</td>\n      <td>RIEHLE 1-08</td>\n      <td>43.300821</td>\n      <td>-105.049454</td>\n      <td>4794221.757</td>\n      <td>495989.6569</td>\n      <td>10-15-1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>WAYPOINT</td>\n      <td>RIEHLE 1-06</td>\n      <td>43.299888</td>\n      <td>-105.050330</td>\n      <td>4794118.185</td>\n      <td>495918.5425</td>\n      <td>WF</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>WAYPOINT</td>\n      <td>RIEHLE 1-05</td>\n      <td>43.299390</td>\n      <td>-105.050454</td>\n      <td>4794062.887</td>\n      <td>495908.4514</td>\n      <td>15-8-1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>WAYPOINT</td>\n      <td>RIEHLE 1-02</td>\n      <td>43.298728</td>\n      <td>-105.050197</td>\n      <td>4793989.382</td>\n      <td>495929.2187</td>\n      <td>8-14-2.5</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>WAYPOINT</td>\n      <td>RIEHLE 1-03</td>\n      <td>43.298965</td>\n      <td>-105.050397</td>\n      <td>4794015.678</td>\n      <td>495913.0101</td>\n      <td>12.5-17-2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>WAYPOINT</td>\n      <td>RIEHLE 1-101</td>\n      <td>43.295872</td>\n      <td>-105.048572</td>\n      <td>4793672.122</td>\n      <td>496060.8806</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>WAYPOINT</td>\n      <td>RIEHLE 1-102</td>\n      <td>43.296017</td>\n      <td>-105.048671</td>\n      <td>4793688.225</td>\n      <td>496052.8807</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>WAYPOINT</td>\n      <td>RIEHLE 1-103</td>\n      <td>43.296140</td>\n      <td>-105.048585</td>\n      <td>4793701.847</td>\n      <td>496059.8165</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>WAYPOINT</td>\n      <td>RIEHLE 1-104</td>\n      <td>43.296230</td>\n      <td>-105.048663</td>\n      <td>4793711.847</td>\n      <td>496053.5120</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>WAYPOINT</td>\n      <td>RIEHLE 1-109</td>\n      <td>43.296734</td>\n      <td>-105.048855</td>\n      <td>4793767.847</td>\n      <td>496037.9898</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>WAYPOINT</td>\n      <td>RIEHLE 1-108</td>\n      <td>43.296600</td>\n      <td>-105.048807</td>\n      <td>4793753.018</td>\n      <td>496041.8808</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>WAYPOINT</td>\n      <td>RIEHLE 1-107</td>\n      <td>43.296550</td>\n      <td>-105.048807</td>\n      <td>4793747.398</td>\n      <td>496041.8808</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>WAYPOINT</td>\n      <td>RIEHLE 1-106</td>\n      <td>43.296455</td>\n      <td>-105.048612</td>\n      <td>4793736.827</td>\n      <td>496057.7109</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>WAYPOINT</td>\n      <td>RIEHLE 1-100</td>\n      <td>43.295859</td>\n      <td>-105.048531</td>\n      <td>4793670.706</td>\n      <td>496064.2344</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>WAYPOINT</td>\n      <td>RIEHLE 1-105</td>\n      <td>43.296445</td>\n      <td>-105.048622</td>\n      <td>4793735.773</td>\n      <td>496056.8265</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>WAYPOINT</td>\n      <td>Riehle 1-110</td>\n      <td>43.297916</td>\n      <td>-105.049595</td>\n      <td>4793899.195</td>\n      <td>495978.0270</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>WAYPOINT</td>\n      <td>RIEHLE 1-111</td>\n      <td>43.298726</td>\n      <td>-105.050188</td>\n      <td>4793989.098</td>\n      <td>495929.9958</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>WAYPOINT</td>\n      <td>RIEHLE 1-112</td>\n      <td>43.299875</td>\n      <td>-105.050298</td>\n      <td>4794116.776</td>\n      <td>495921.0939</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"The structure data is not very useful in it's current form as the positions of the strutcure do not fall on the stream path. We will need to develop an algorythm to calculate the closest points along the stream path which would correspond to the strutcure locations.","metadata":{}},{"cell_type":"code","source":"def get_closest_points (stream_path, structure_points):\n    closest_points = []\n    for x, y in structure_points:\n        min_distance = float('inf')\n        for x1, y1 in stream_path:\n            distance = ((x1 - x)**2 + (y1 - y)**2)**0.5\n            if distance < min_distance:\n                min_distance = distance\n                close_point_pair = [x1, y1]\n        closest_points.append(close_point_pair)\n    return closest_points","metadata":{"execution":{"iopub.status.busy":"2024-04-22T17:22:53.856554Z","iopub.execute_input":"2024-04-22T17:22:53.857249Z","iopub.status.idle":"2024-04-22T17:22:53.863029Z","shell.execute_reply.started":"2024-04-22T17:22:53.857217Z","shell.execute_reply":"2024-04-22T17:22:53.862065Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"This function takes the stream path and the structure points then performs the pythagorean theorem on to calculate the euclidian distance between the current structure and all points along the stream path. It finds the shortest distance and adds that point along the stream path to the closest points array. This array ends with a collection of the closest points to each structure.","metadata":{}},{"cell_type":"markdown","source":"Next I need to create a function that will create an array from each dataframe so we can feed the appropriate data structure into the `get_closest_points` function.","metadata":{}},{"cell_type":"code","source":" def zip_df_cols(dataframe):\n    array = []\n    for x,y in zip(dataframe['X'], dataframe['Y']):\n        array.append([float(x), float(y)])\n    return array\n\nstructures_array = zip_df_cols(structures_df)\nstream_profile_array = zip_df_cols(stream_profile_df)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T17:22:54.656236Z","iopub.execute_input":"2024-04-22T17:22:54.656923Z","iopub.status.idle":"2024-04-22T17:22:54.662893Z","shell.execute_reply.started":"2024-04-22T17:22:54.656893Z","shell.execute_reply":"2024-04-22T17:22:54.661907Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Now we can find the closest points along the stream profile that correspond to the structures","metadata":{}},{"cell_type":"code","source":"closest_profile_points = get_closest_points(stream_profile_array, structures_array)\nprint(closest_profile_points)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T17:22:55.213900Z","iopub.execute_input":"2024-04-22T17:22:55.214502Z","iopub.status.idle":"2024-04-22T17:22:55.228670Z","shell.execute_reply.started":"2024-04-22T17:22:55.214473Z","shell.execute_reply":"2024-04-22T17:22:55.227707Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"[[495968.4379, 4794196.563], [495909.7792, 4794022.362], [495954.9406, 4793957.022], [495998.0819, 4794269.644], [495990.7051, 4794221.647], [495920.4458, 4794117.176], [495906.7227, 4794063.485], [495928.4509, 4793989.593], [495913.6466, 4794015.625], [496065.5786, 4793674.139], [496059.2641, 4793690.376], [496059.4445, 4793702.284], [496056.1369, 4793712.928], [496037.4699, 4793768.28], [496040.0949, 4793752.89], [496042.6659, 4793747.388], [496057.2795, 4793736.202], [496067.0219, 4793671.072], [496057.2795, 4793736.202], [495977.3133, 4793899.187], [495929.3658, 4793988.304], [495920.4458, 4794117.176]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We now have an array of the closest points along the stream profile that correspond to our structures. We can note that the first structure falls out of the range of our stream profile so we can neglect this point.","metadata":{}},{"cell_type":"code","source":"closest_profile_points = closest_profile_points[1:]\nlen(closest_profile_points)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T17:22:55.709471Z","iopub.execute_input":"2024-04-22T17:22:55.710099Z","iopub.status.idle":"2024-04-22T17:22:55.715752Z","shell.execute_reply.started":"2024-04-22T17:22:55.710067Z","shell.execute_reply":"2024-04-22T17:22:55.714824Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"21"},"metadata":{}}]},{"cell_type":"markdown","source":"Now let's package this whole process as a function to allow us to repeat it for every section of stream.","metadata":{}},{"cell_type":"code","source":"import re\nfrom typing import List, Tuple\n\nclass New_Dataframe:\n    \n    def split_profile_and_structures(self, data_list_array: List[str]) -> Tuple[List[str], List[str]]:\n        \"\"\"\n        Splits a list of strings into two lists: profile_list and structure_list.\n\n        Args:\n            data_list_array (List[str]): A list of strings to be split.\n\n        Returns:\n            Tuple[List[str], List[str]]: A tuple containing the profile_list and structure_list.\n        \"\"\"\n        \n        profile_list = []\n        structure_list = []\n        \n        for item in data_list_array:\n            if 'Long' in item:\n                profile_list.append(item)\n            else:\n                structure_list.append(item)\n        return profile_list, structure_list\n    \n    def pair_profile_and_structure(self,datalist: List[str]) -> List[List[List[str]]]:\n        \n        \"\"\"\n        Pairs profile and structure items from a list of strings.\n\n        Args:\n            datalist (List[str]): A list of strings containing profile and structure items.\n\n        Returns:\n            List[List[List[str]]]: A list of pairs of profile and structure items.\n        \"\"\"\n        \n        profile_list, structure_list = self.split_profile_and_structures(datalist)\n        profile_structure_pair_arr = []\n        \n        for stream_profile in profile_list:\n            profile_structure_pair = [stream_profile]\n            search_pattern = r'\\d+[A-Z]?(?=_)'\n            match = re.search(search_pattern, stream_profile)\n            \n            if match:\n                stream_section = match.group()\n            \n            for structure in structure_list:\n                if stream_section in structure:\n                    profile_structure_pair.append(structure)\n                    profile_structure_pair_arr.append(profile_structure_pair)\n                    break\n            \n        return profile_structure_pair_arr\n  \n    def get_closest_points(self, stream_path_df: pd.DataFrame, structure_df: pd.DataFrame) -> List[List[float]]:\n        \"\"\"\n        Finds the closest points between the stream_path_df and structure_df.\n\n        Args:\n            stream_path_df (pd.DataFrame): The DataFrame containing the stream path data.\n            structure_df (pd.DataFrame): The DataFrame containing the structure data.\n\n        Returns:\n            List[List[float]]: A list of closest points, where each point is a list of [x, y] coordinates.\n        \"\"\"\n        closest_points = []\n        for i in range(len(structure_df['x_proj'])):\n            structure_x = structure_df['x_proj'].iloc[i]\n            structure_y = structure_df['y_proj'].iloc[i]\n\n            min_dist = float('inf')\n\n            for j in range(len(stream_path_df['X'])):\n                stream_path_x = stream_path_df['X'].iloc[j]\n                stream_path_y = stream_path_df['Y'].iloc[j]\n                dist = ((structure_x - stream_path_x)**2 + (structure_y - stream_path_y)**2)**0.5\n                \n                if dist < min_dist:\n                    min_dist = dist\n                    closest_point = [stream_path_x, stream_path_y]\n                    \n            closest_points.append(closest_point)\n        return closest_points\n    \n    def create_headcut_bools(self, stream_path_df: pd.DataFrame, closest_points: List[List[float]]) -> pd.DataFrame:\n        \"\"\"\n        Adds a 'has headcut' column to the stream_path_df based on the closest points.\n\n        Args:\n            stream_path_df (pd.DataFrame): The DataFrame containing the stream path data.\n            closest_points (List[List[float]]): A list of closest points, where each point is a list of [x, y] coordinates.\n\n        Returns:\n            pd.DataFrame: The modified stream_path_df with the 'has headcut' column added.\n        \"\"\"\n        for i in range(len(stream_path_df)):\n            x_val, y_val = stream_path_df['X'].iloc[i], stream_path_df['Y'].iloc[i]\n            has_headcut_bool = False\n            for j in range(len(closest_points)):\n                if closest_points[j][0] == x_val and closest_points[j][1] == y_val:\n                    has_headcut_bool = True\n                    break\n            stream_path_df.at[i, 'has headcut'] = 1 if has_headcut_bool else 0\n        return stream_path_df\n    \n    def calc_slope(self, stream_path_df: pd.DataFrame, slope_gap: int) -> pd.DataFrame:\n        \"\"\"\n        Calculates the slope at each point in the stream_path_df using the given slope_gap.\n\n        Args:\n            stream_path_df (pd.DataFrame): The DataFrame containing the stream path data.\n            slope_gap (int): The number of points to consider for the slope calculation.\n\n        Returns:\n            pd.DataFrame: The modified stream_path_df with the slope columns added.\n        \"\"\"\n        stream_length = len(stream_path_df['X'])\n        \n        for i in range(stream_length):\n            index_1 = max(0, i-slope_gap)\n            index_2 = min(stream_length - 1, i+slope_gap)\n            dist_delta = stream_path_df['Dist M'].iloc[index_2] - stream_path_df['Dist M'].iloc[index_1]\n            elev_delta = stream_path_df['Elev Ft'].iloc[index_2] - stream_path_df['Elev Ft'].iloc[index_1]\n            \n            if dist_delta == 0:\n                slope = 0\n                print(f\"dist_delta = 0  at {i}\")\n            else:\n                slope = elev_delta/dist_delta\n            column_title = f\"Slope Gap: {slope_gap}\"\n            stream_path_df.at[i, column_title] = slope\n        \n        return stream_path_df\n    \n    def get_avg_slopes(self, stream_path_df: pd.DataFrame, slope_arr: List[int] = [1, 5, 10, 15]) -> pd.DataFrame:\n        \"\"\"\n        Calculates the average slope for the given slope_arr and adds the slope columns to the stream_path_df.\n\n        Args:\n            stream_path_df (pd.DataFrame): The DataFrame containing the stream path data.\n            slope_arr (List[int]): A list of slope gap values to calculate the slopes for.\n\n        Returns:\n            pd.DataFrame: The modified stream_path_df with the average slope columns added.\n        \"\"\"\n        for slope_gap in slope_arr:\n            stream_path_df = self.calc_slope(stream_path_df, slope_gap)\n        return stream_path_df\n    \n    def create_final_dataframe(self, datalist: List[str]) -> pd.DataFrame:\n        \"\"\"\n        Creates the final DataFrame by processing the input datalist.\n\n        Args:\n            datalist (List[str]): A list of file paths or other data.\n\n        Returns:\n            pd.DataFrame: The final consolidated DataFrame.\n        \"\"\"\n        \n        profile_structure_list = self.pair_profile_and_structure(datalist)\n        final_df = pd.DataFrame()\n        first_pass = True\n\n        for pair in profile_structure_list:\n            stream_path = pair[0]\n            structure = pair[1]\n\n#             stream_path_df = pd.read_csv(stream_path)\n#             structure_df = pd.read_csv(structure)\n\n            try:\n                stream_path_df = pd.read_csv(stream_path)\n                print(f\"Successfully read {stream_path}\")\n            except Exception as e:\n                print(f\"Error reading {stream_path}: {e}\")\n                continue\n\n            try:\n                structure_df = pd.read_csv(structure)\n                print(f\"Successfully read {structure}\")\n            except Exception as e:\n                print(f\"Error reading {structure}: {e}\")\n                continue\n                \n                \n            \n            closest_structure_points = self.get_closest_points(stream_path_df, structure_df)\n            \n            if stream_path_df is None:\n                print(f\"stream_path_df is None for {stream_path_df}\")\n                continue\n            \n            stream_path_df = self.create_headcut_bools(stream_path_df, closest_structure_points)\n            \n            if stream_path_df is None:\n                print(f\"stream_path_df is None for headcut_bools {stream_path_df}\")\n                continue\n                \n            stream_path_df = self.get_avg_slopes(stream_path_df)\n            \n            if stream_path_df is None:\n                print(f\"stream_path_df is None for avg_slope {stream_path_df}\")\n                continue\n            \n            # Check if the dataframes have numerical columns\n            if first_pass:\n                # Use the column titles from the first stream_path_df\n                final_df = pd.DataFrame(columns=stream_path_df.columns)\n                first_pass = False\n                \n            if not first_pass:\n                stream_path_df.drop(index=0)\n            \n            if all(stream_path_df.dtypes == float) and all(structure_df.dtypes == float):\n                stream_path_df = stream_path_df.astype(float)\n                structure_df = structure_df.astype(float)\n            else:\n                # If the dataframes have non-numerical columns, drop them\n                stream_path_df = stream_path_df.select_dtypes(include='number').astype(float)\n                structure_df = structure_df.select_dtypes(include='number').astype(float)\n\n            \n\n            \n\n            final_df = pd.concat([final_df, stream_path_df], ignore_index=True)\n\n        return final_df\n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-22T17:22:56.293821Z","iopub.execute_input":"2024-04-22T17:22:56.294169Z","iopub.status.idle":"2024-04-22T17:22:56.324677Z","shell.execute_reply.started":"2024-04-22T17:22:56.294144Z","shell.execute_reply":"2024-04-22T17:22:56.323738Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import os\n\ntotal_df = New_Dataframe()\nstream_structure_dataset = []\n\nfor dirname, _, filenames in os.walk('/kaggle/input/headcut-collection'):\n    for filename in filenames:\n        file = os.path.join(dirname, filename)\n        stream_structure_dataset.append(file)\n\nstream_df_new = total_df.create_final_dataframe(stream_structure_dataset)\nstream_df_new","metadata":{"execution":{"iopub.status.busy":"2024-04-22T17:23:57.998321Z","iopub.execute_input":"2024-04-22T17:23:57.999039Z","iopub.status.idle":"2024-04-22T17:24:00.619979Z","shell.execute_reply.started":"2024-04-22T17:23:57.999007Z","shell.execute_reply":"2024-04-22T17:24:00.619087Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Successfully read /kaggle/input/headcut-collection/Headcut CSVs/Riehle_3_Long_Pro.csv\nSuccessfully read /kaggle/input/headcut-collection/Headcut CSVs/Riehle_3_Project_Structures.csv\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_163/944580302.py:230: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  final_df = pd.concat([final_df, stream_path_df], ignore_index=True)\n","output_type":"stream"},{"name":"stdout","text":"Successfully read /kaggle/input/headcut-collection/Headcut CSVs/Riehle_4_Long_Pro.csv\nSuccessfully read /kaggle/input/headcut-collection/Headcut CSVs/Riehle_4_Project_Structures.csv\nSuccessfully read /kaggle/input/headcut-collection/Headcut CSVs/Riehle_2B_Long_Pro.csv\nSuccessfully read /kaggle/input/headcut-collection/Headcut CSVs/Riehle_2B_Project_Structures.csv\nSuccessfully read /kaggle/input/headcut-collection/Headcut CSVs/Riehle_2A_Long_Pro.csv\nSuccessfully read /kaggle/input/headcut-collection/Headcut CSVs/Riehle_2A_Project_Structures.csv\nSuccessfully read /kaggle/input/headcut-collection/Headcut CSVs/Riehle_1B_Long_Pro.csv\nSuccessfully read /kaggle/input/headcut-collection/Headcut CSVs/Riehle_1B_Project_Structures.csv\nSuccessfully read /kaggle/input/headcut-collection/Headcut CSVs/Riehle_1A_Long_Pro.csv\nSuccessfully read /kaggle/input/headcut-collection/Headcut CSVs/Riehle_1A_Project_Structures.csv\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"          Dist M            X            Y      Elev Ft  has headcut  \\\n0       0.000000  495684.6380  4794395.746  4886.384766          1.0   \n1       1.043499  495684.6380  4794394.702  4886.253418          0.0   \n2       2.086998  495684.6380  4794393.659  4886.187988          0.0   \n3       3.130497  495684.6380  4794392.615  4885.958008          0.0   \n4       4.586810  495684.8439  4794391.174  4885.433105          0.0   \n...          ...          ...          ...          ...          ...   \n2615  422.960557  496011.6344  4793816.487  4807.415039          0.0   \n2616  424.102494  496011.4540  4793815.359  4807.382324          0.0   \n2617  425.244431  496011.2736  4793814.231  4807.349121          0.0   \n2618  426.386369  496011.0932  4793813.104  4807.283691          0.0   \n2619  427.528305  496010.9128  4793811.976  4806.955566          0.0   \n\n      Slope Gap: 1  Slope Gap: 5  Slope Gap: 10  Slope Gap: 15  \n0        -0.125873     -0.222603      -0.305488      -0.244375  \n1        -0.094288     -0.312158      -0.286685      -0.241834  \n2        -0.141548     -0.298615      -0.266490      -0.228256  \n3        -0.301976     -0.318961      -0.255804      -0.222257  \n4        -0.315336     -0.325182      -0.240867      -0.216865  \n...            ...           ...            ...            ...  \n2615     -0.099036     -0.116222      -0.100167      -0.102911  \n2616     -0.028862     -0.088500      -0.103653      -0.103710  \n2617     -0.043187     -0.101351      -0.098387      -0.102230  \n2618     -0.172319     -0.104313      -0.094699      -0.105570  \n2619     -0.287341     -0.114268      -0.107175      -0.102172  \n\n[2620 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dist M</th>\n      <th>X</th>\n      <th>Y</th>\n      <th>Elev Ft</th>\n      <th>has headcut</th>\n      <th>Slope Gap: 1</th>\n      <th>Slope Gap: 5</th>\n      <th>Slope Gap: 10</th>\n      <th>Slope Gap: 15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>495684.6380</td>\n      <td>4794395.746</td>\n      <td>4886.384766</td>\n      <td>1.0</td>\n      <td>-0.125873</td>\n      <td>-0.222603</td>\n      <td>-0.305488</td>\n      <td>-0.244375</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.043499</td>\n      <td>495684.6380</td>\n      <td>4794394.702</td>\n      <td>4886.253418</td>\n      <td>0.0</td>\n      <td>-0.094288</td>\n      <td>-0.312158</td>\n      <td>-0.286685</td>\n      <td>-0.241834</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.086998</td>\n      <td>495684.6380</td>\n      <td>4794393.659</td>\n      <td>4886.187988</td>\n      <td>0.0</td>\n      <td>-0.141548</td>\n      <td>-0.298615</td>\n      <td>-0.266490</td>\n      <td>-0.228256</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.130497</td>\n      <td>495684.6380</td>\n      <td>4794392.615</td>\n      <td>4885.958008</td>\n      <td>0.0</td>\n      <td>-0.301976</td>\n      <td>-0.318961</td>\n      <td>-0.255804</td>\n      <td>-0.222257</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.586810</td>\n      <td>495684.8439</td>\n      <td>4794391.174</td>\n      <td>4885.433105</td>\n      <td>0.0</td>\n      <td>-0.315336</td>\n      <td>-0.325182</td>\n      <td>-0.240867</td>\n      <td>-0.216865</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2615</th>\n      <td>422.960557</td>\n      <td>496011.6344</td>\n      <td>4793816.487</td>\n      <td>4807.415039</td>\n      <td>0.0</td>\n      <td>-0.099036</td>\n      <td>-0.116222</td>\n      <td>-0.100167</td>\n      <td>-0.102911</td>\n    </tr>\n    <tr>\n      <th>2616</th>\n      <td>424.102494</td>\n      <td>496011.4540</td>\n      <td>4793815.359</td>\n      <td>4807.382324</td>\n      <td>0.0</td>\n      <td>-0.028862</td>\n      <td>-0.088500</td>\n      <td>-0.103653</td>\n      <td>-0.103710</td>\n    </tr>\n    <tr>\n      <th>2617</th>\n      <td>425.244431</td>\n      <td>496011.2736</td>\n      <td>4793814.231</td>\n      <td>4807.349121</td>\n      <td>0.0</td>\n      <td>-0.043187</td>\n      <td>-0.101351</td>\n      <td>-0.098387</td>\n      <td>-0.102230</td>\n    </tr>\n    <tr>\n      <th>2618</th>\n      <td>426.386369</td>\n      <td>496011.0932</td>\n      <td>4793813.104</td>\n      <td>4807.283691</td>\n      <td>0.0</td>\n      <td>-0.172319</td>\n      <td>-0.104313</td>\n      <td>-0.094699</td>\n      <td>-0.105570</td>\n    </tr>\n    <tr>\n      <th>2619</th>\n      <td>427.528305</td>\n      <td>496010.9128</td>\n      <td>4793811.976</td>\n      <td>4806.955566</td>\n      <td>0.0</td>\n      <td>-0.287341</td>\n      <td>-0.114268</td>\n      <td>-0.107175</td>\n      <td>-0.102172</td>\n    </tr>\n  </tbody>\n</table>\n<p>2620 rows Ã— 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Now let's add a column to our stream profile called `has_headcut`. This will be our dependent variable for our machine learning model.","metadata":{}},{"cell_type":"code","source":"for i in range(len(stream_profile_df['X'])):\n    x_val, y_val = float(stream_profile_df['X'].iloc[i]), float(stream_profile_df['Y'].iloc[i])\n    has_headcut_bool = False\n    for j in range(len(closest_profile_points)):\n        if closest_profile_points[j][0] == x_val and closest_profile_points[j][1] == y_val:\n            has_headcut_bool = True\n            break\n    stream_profile_df.at[i, 'has headcut'] = 1 if has_headcut_bool else 0\n\n    \nheadcut_rows = stream_profile_df[stream_profile_df['has headcut'] == 1]\nheadcut_rows","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum(stream_profile_df['has headcut'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We now have a column with our dependent variable `has headcut` this is the variable we will try to predict with our machine learning models. The next steps are to do some data analysis, calculating slopes at each point, and average slopes at each point with varying distance widths (5, 10, 15, 20). This will give us more columns that our machine learning model can use to sort potential headcuts and non-headcut areas.","metadata":{}},{"cell_type":"code","source":"def avg_slope(title, gap):\n    for i in range(len(stream_profile_df['Elev ft'])):\n        min_i = max(0, i-gap)\n        max_i = min(len(stream_profile_df['Elev ft'])-1, i+gap)\n        \n        dist_min = float(stream_profile_df['Dist M'].iloc[min_i])\n        dist_max = float(stream_profile_df['Dist M'].iloc[max_i])\n        elev_min = float(stream_profile_df['Elev ft'].iloc[min_i])\n        elev_max = float(stream_profile_df['Elev ft'].iloc[max_i])\n        \n        \n        numerator = elev_max - elev_min\n        denominator = dist_max - dist_min\n        if abs(denominator) > 1e-6:\n            slope = numerator/denominator\n        else: \n            slope = 0.0\n        stream_profile_df.at[i, title] = slope\n#         print(f\"Row {i}: numerator={numerator}, denominator={denominator}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"avg_slope('Slope at Point', 1) # Slope at point\navg_slope('Avg Slope 10m', 5) # Slope at point\navg_slope('Avg Slope 20m', 10) # Slope at point\navg_slope('Avg Slope 30m', 15) # Slope at point\n\n    \nheadcut_rows = stream_profile_df[stream_profile_df['has headcut'] == 1]\nheadcut_rows\n\nheadcut_rows","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Before we can convert this dataframe into a tensor, we need to make sure that all columns contain floats to allow the tensor to perform operations on them. We can use the `.dtypes` function to check what our datatypes are for various columns.","metadata":{}},{"cell_type":"code","source":"stream_profile_df = stream_profile_df.fillna(stream_profile_df.mode().iloc[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stream_profile_df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see the columns `Dist M, X, Y, Elev ft` are all objects. We can use `.astype(float)` to convert these to floats instead\n","metadata":{}},{"cell_type":"code","source":"stream_profile_df['Dist M'] = stream_profile_df['Dist M'].astype(float)\nstream_profile_df['X'] = stream_profile_df['X'].astype(float)\nstream_profile_df['Y'] = stream_profile_df['Y'].astype(float)\nstream_profile_df['Elev ft'] = stream_profile_df['Elev ft'].astype(float)\nstream_profile_df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we have our cleaned up data and several average slope columns. Let's try making a linear model and see what kind of predictive accuracy we can achieve.","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import tensor\nt_dep = tensor(stream_profile_df['has headcut'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indep_columns = ['Dist M', 'X', 'Y', 'Elev ft',\t'Slope at Point','Avg Slope 10m','Avg Slope 20m','Avg Slope 30m']\nt_indep = tensor(stream_profile_df[indep_columns].values, dtype=torch.float)\nt_indep","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t_indep.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating a Linear Model","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(27)\nn_coeff = t_indep.shape[1]\ncoeffs = torch.rand(n_coeff)-0.5\ncoeffs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t_indep*coeffs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t_indep[t_indep == 0] = 1e-6\n\nvals,indices = t_indep.max(dim=0)\nt_indep = t_indep / vals","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t_indep*coeffs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = (t_indep*coeffs).sum(axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t_dep.shape, preds.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = torch.abs(preds-t_dep).mean()\nloss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_preds(coeffs, indeps): return (indeps*coeffs).sum(axis=1)\ndef calc_loss(coeffs, indeps, deps): return torch.abs(calc_preds(coeffs, indeps)-deps).mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Doing a gradient descent step","metadata":{}},{"cell_type":"code","source":"coeffs.requires_grad_()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = calc_loss(coeffs, t_indep, t_dep)\nloss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"coeffs.grad","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = calc_loss(coeffs, t_indep, t_dep)\nloss.backward()\ncoeffs.grad","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = calc_loss(coeffs, t_indep, t_dep)\nloss.backward()\nwith torch.no_grad():\n    coeffs.sub_(coeffs.grad * 0.1)\n    coeffs.grad.zero_()\n    print(calc_loss(coeffs, t_indep, t_dep))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training a Linear Model","metadata":{}},{"cell_type":"code","source":"\nfrom fastai.data.transforms import RandomSplitter\ntrn_split, val_split = RandomSplitter(seed=27)(stream_profile_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn_indep, val_indep = t_indep[trn_split], t_indep[val_split]\ntrn_dep, val_dep = t_dep[trn_split], t_dep[val_split]\nlen(trn_indep), len(val_indep)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def update_coeffs(coeffs, lr):\n    coeffs.sub_(coeffs * lr)\n    coeffs.grad.zero_()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def one_epoch(coeffs, lr):\n    loss = calc_loss(coeffs, trn_indep, trn_dep)\n    loss.backward()\n    with torch.no_grad(): update_coeffs(coeffs, lr)\n    print(f\"{loss:3f}\", end=\"; \")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def init_coeffs(): return (torch.rand(n_coeff)-0.5).requires_grad_()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(epochs=30, lr = 0.01):\n    torch.manual_seed(27)\n    coeffs = init_coeffs()\n    for i in range(epochs): one_epoch(coeffs, lr=lr)\n    return coeffs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"coeffs = train_model(18, lr=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = calc_preds(coeffs, val_indep)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = val_dep.bool()==(preds>0.5)\nresults[:16]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results.float().mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def acc(coeffs): return (val_dep.bool()==calc_preds(coeffs, val_indep)).float().mean()\nacc(coeffs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds[:28]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_preds(coeffs, indeps): return torch.sigmoid((indeps*coeffs).sum(axis=1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"coeffs = train_model(lr=0.25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc(coeffs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}